% Generated by Paperpile. Check out https://paperpile.com for more information.
% BibTeX export options can be customized via Settings -> BibTeX.

@ARTICLE{Liu2022-ie,
  title     = "Trustworthy {AI}: A Computational Perspective",
  author    = "Liu, Haochen and Wang, Yiqi and Fan, Wenqi and Liu, Xiaorui and
               Li, Yaxin and Jain, Shaili and Liu, Yunhao and Jain, Anil K and
               Tang, Jiliang",
  abstract  = "In the past few decades, artificial intelligence (AI) technology
               has experienced swift developments, changing everyone's daily
               life and profoundly altering the course of human society. The
               intention behind developing AI was and is to benefit humans by
               reducing labor, increasing everyday conveniences, and promoting
               social good. However, recent research and AI applications
               indicate that AI can cause unintentional harm to humans by, for
               example, making unreliable decisions in safety-critical
               scenarios or undermining fairness by inadvertently
               discriminating against a group or groups. Consequently,
               trustworthy AI has recently garnered increased attention
               regarding the need to avoid the adverse effects that AI could
               bring to people, so people can fully trust and live in harmony
               with AI technologies. A tremendous amount of research on
               trustworthy AI has been conducted and witnessed in recent years.
               In this survey, we present a comprehensive appraisal of
               trustworthy AI from a computational perspective to help readers
               understand the latest technologies for achieving trustworthy AI.
               Trustworthy AI is a large and complex subject, involving various
               dimensions. In this work, we focus on six of the most crucial
               dimensions in achieving trustworthy AI: (i) Safety \&
               Robustness, (ii) Nondiscrimination \& Fairness, (iii)
               Explainability, (iv) Privacy, (v) Accountability \&
               Auditability, and (vi) Environmental Well-being. For each
               dimension, we review the recent related technologies according
               to a taxonomy and summarize their applications in real-world
               systems. We also discuss the accordant and conflicting
               interactions among different dimensions and discuss potential
               aspects for trustworthy AI to investigate in the future.",
  journal   = "ACM Trans. Intell. Syst. Technol.",
  publisher = "Association for Computing Machinery",
  month     =  jun,
  year      =  2022,
  address   = "New York, NY, USA",
  keywords  = "artificial intelligence, privacy, robustness, accountability,
               fairness, explainability, environmental well-being",
  url       = {https://dl.acm.org/doi/10.1145/3546872}
}



@INPROCEEDINGS{Toreini2020-fj,
  title     = "The relationship between trust in {AI} and trustworthy machine
               learning technologies",
  booktitle = "Proceedings of the 2020 Conference on Fairness, Accountability,
               and Transparency",
  author    = "Toreini, Ehsan and Aitken, Mhairi and Coopamootoo, Kovila and
               Elliott, Karen and Zelaya, Carlos Gonzalez and van Moorsel, Aad",
  abstract  = "To design and develop AI-based systems that users and the larger
               public can justifiably trust, one needs to understand how
               machine learning technologies impact trust. To guide the design
               and implementation of trusted AI-based systems, this paper
               provides a systematic approach to relate considerations about
               trust from the social sciences to trustworthiness technologies
               proposed for AI-based services and products. We start from the
               ABI+ (Ability, Benevolence, Integrity, Predictability) framework
               augmented with a recently proposed mapping of ABI+ on qualities
               of technologies that support trust. We consider four categories
               of trustworthiness technologies for machine learning, namely
               these for Fairness, Explainability, Auditability and Safety
               (FEAS) and discuss if and how these support the required
               qualities. Moreover, trust can be impacted throughout the life
               cycle of AI-based systems, and we therefore introduce the
               concept of Chain of Trust to discuss trustworthiness
               technologies in all stages of the life cycle. In so doing we
               establish the ways in which machine learning technologies
               support trusted AI-based systems. Finally, FEAS has obvious
               relations with known frameworks and therefore we relate FEAS to
               a variety of international 'principled AI' policy and technology
               frameworks that have emerged in recent years.",
  publisher = "Association for Computing Machinery",
  pages     = "272--283",
  series    = "FAT* '20",
  month     =  jan,
  year      =  2020,
  address   = "New York, NY, USA",
  keywords  = "trustworthiness, artificial intelligence, machine learning,
               trust;Trusted AI;TAI Framework",
  location  = "Barcelona, Spain",
  url       = {https://dl.acm.org/doi/abs/10.1145/3351095.3372834}
}

@INPROCEEDINGS{Thornton2021-hk,
  title     = "Fifty Shades of Grey: In Praise of a Nuanced Approach Towards
               Trustworthy Design",
  booktitle = "Proceedings of the 2021 {ACM} Conference on Fairness,
               Accountability, and Transparency",
  author    = "Thornton, Lauren and Knowles, Bran and Blair, Gordon",
  abstract  = "Environmental data science is uniquely placed to respond to
               essentially complex and fantastically worthy challenges related
               to arresting planetary destruction. Trust is needed for
               facilitating collaboration between scientists who may share
               datasets and algorithms, and for crafting appropriate
               science-based policies. Achieving this trust is particularly
               challenging because of the numerous complexities, multi-scale
               variables, interdependencies and multi-level uncertainties
               inherent in environmental data science. Virtual Labs---easily
               accessible online environments provisioning access to datasets,
               analysis and visualisations---are socio-technical systems which,
               if carefully designed, might address these challenges and
               promote trust in a variety of ways. In addition to various
               system properties that can be utilised in support of effective
               collaboration, certain features which are commonly seen to
               benefit trust---transparency and provenance in
               particular---appear applicable to promoting trust in and through
               Virtual Labs. Attempting to realise these features in their
               design reveals, however, that their implementation is more
               nuanced and complex than it would appear. Using the lens of
               affordances, we argue for the need to carefully articulate these
               features, with consideration of multiple stakeholder needs on
               balance, so that these Virtual Labs do in fact promote trust. We
               argue that these features not be conceived as widgets that can
               be imported into a given context to promote trust; rather,
               whether they promote trust is a function of how systematically
               designers consider various (potentially conflicting) stakeholder
               trust needs.",
  publisher = "Association for Computing Machinery",
  pages     = "64--76",
  series    = "FAccT '21",
  month     =  mar,
  year      =  2021,
  address   = "New York, NY, USA",
  keywords  = "Affordances, Trust, Environmental Data Science, Virtual Research
               Environments;Trusted AI;TAI Framework",
  location  = "Virtual Event, Canada",
  url       = {https://eprints.lancs.ac.uk/id/eprint/150106/}
}

@BOOK{Corporate-body_CNECTDirectorate-General_for_Communications_Networks2019-gd,
  title     = "Ethics guidelines for trustworthy {AI}",
  author    = "{corporate-body. CNECT:Directorate-General for Communications
               Networks} and {Content} and {Technology} and {null.agent.Grupa
               ekspert{\'o}w wysokiego szczebla ds. sztucznej
               inteligencji:Grupa ekspert{\'o}w wysokiego szczebla ds.
               sztucznej inteligencji}",
  abstract  = "The aim of the Guidelines is to promote Trustworthy AI.
               Trustworthy AI has three components, which should be met
               throughout the system's entire life cycle: (1) it should be
               lawful, complying with all applicable laws and regulations (2)
               it should be ethical, ensuring adherence to ethical principles
               and values and (3) it should be robust, both from a technical
               and social perspective since, even with good intentions, AI
               systems can cause unintentional harm. Each component in itself
               is necessary but not sufficient for the achievement of
               Trustworthy AI. Ideally, all three components work in harmony
               and overlap in their operation. If, in practice, tensions arise
               between these components, society should endeavour to align
               them.",
  publisher = "Publications Office of the European Union",
  month     =  nov,
  year      =  2019,
  keywords  = "Trusted AI;TAI Framework",
  language  = "en"
}

@TECHREPORT{Smuha_undated-da,
  title     = "Ethics guidelines for trustworthy {AI}",
  editor    = "Smuha, Nathalie",
  abstract  = "On 8 April 2019, the High-Level Expert Group on AI presented
               Ethics Guidelines for Trustworthy Artificial Intelligence. This
               followed the publication of the guidelines' first draft in
               December 2018 on which more than 500 comments were received
               through an open consultation.",
  publisher = "European Commission",
  keywords  = "TAI Framework",
  language  = "en",
  url       = {https://digital-strategy.ec.europa.eu/en/library/ethics-guidelines-trustworthy-ai}
}

@ARTICLE{Liang2022-yz,
  title     = "Advances, challenges and opportunities in creating data for
               trustworthy {AI}",
  author    = "Liang, Weixin and Tadesse, Girmaw Abebe and Ho, Daniel and Li,
               Fei-Fei and Zaharia, Matei and Zhang, Ce and Zou, James",
  abstract  = "As artificial intelligence (AI) transitions from research to
               deployment, creating the appropriate datasets and data pipelines
               to develop and evaluate AI models is increasingly the biggest
               challenge. Automated AI model builders that are publicly
               available can now achieve top performance in many applications.
               In contrast, the design and sculpting of the data used to
               develop AI often rely on bespoke manual work, and they
               critically affect the trustworthiness of the model. This
               Perspective discusses key considerations for each stage of the
               data-for-AI pipeline---starting from data design to data
               sculpting (for example, cleaning, valuation and annotation) and
               data evaluation---to make AI more reliable. We highlight
               technical advances that help to make the data-for-AI pipeline
               more scalable and rigorous. Furthermore, we discuss how recent
               data regulations and policies can impact AI. It has become
               rapidly clear in the past few years that the creation, use and
               maintenance of high-quality annotated datasets for robust and
               reliable AI applications requires careful attention. This
               Perspective discusses challenges, considerations and best
               practices for various stages in the data-to-AI pipeline, to
               encourage a more data-centric approach.",
  journal   = "Nat Mach Intell",
  publisher = "Springer Science and Business Media LLC",
  pages     = "1--9",
  month     =  aug,
  year      =  2022,
  keywords  = "Overleaf;Toward Unified Models;Trusted AI;TAI Framework",
  language  = "en",
  url       = {https://www.nature.com/articles/s42256-022-00516-1}
}

@TECHREPORT{Bowne2022-rc,
  title       = "Implementing Responsible {AI}: Proposed Framework for Data
                 Licensing",
  author      = "Bowne, Andrew and McMartin, Benjamin",
  publisher   = "George Mason University School of Business",
  number      =  10,
  institution = "George Mason University Center for Government Contracting",
  month       =  apr,
  year        =  2022,
  keywords    = "TAI Framework",
  url= {https://business.gmu.edu/news/2022-04/no-10-implementing-responsible-ai-proposed-framework-data-licensing}
}


@ARTICLE{Ilievski2021-eb,
  title    = "Dimensions of commonsense knowledge",
  author   = "Ilievski, Filip and Oltramari, Alessandro and Ma, Kaixin and
              Zhang, Bin and McGuinness, Deborah L and Szekely, Pedro",
  abstract = "Commonsense knowledge is essential for many AI applications,
              including those in natural language processing, visual
              processing, and planning. Consequently, many sources that include
              commonsense knowledge have been designed and constructed over the
              past decades. Recently, the focus has been on large text-based
              sources, which facilitate easier integration with neural
              (language) models and application to textual tasks, typically at
              the expense of the semantics of the sources and their
              harmonization. Efforts to consolidate commonsense knowledge have
              yielded partial success, with no clear path towards a
              comprehensive solution. We aim to organize these sources around a
              common set of dimensions of commonsense knowledge. We survey a
              wide range of popular commonsense sources with a special focus on
              their relations. We consolidate these relations into 13 knowledge
              dimensions. This consolidation allows us to unify the separate
              sources and to compute indications of their coverage, overlap,
              and gaps with respect to the knowledge dimensions. Moreover, we
              analyze the impact of each dimension on downstream reasoning
              tasks that require commonsense knowledge, observing that the
              temporal and desire/goal dimensions are very beneficial for
              reasoning on current downstream tasks, while distinctness and
              lexical knowledge have little impact. These results reveal
              preferences for some dimensions in current evaluation, and
              potential neglect of others.",
  journal  = "Knowledge-Based Systems",
  volume   =  229,
  pages    = "107347",
  month    =  oct,
  year     =  2021,
  keywords = "Commonsense knowledge; Semantics; Knowledge graphs; Reasoning",
  url      = {https://doi.org/10.1016/j.knosys.2021.107347}
}


@TECHREPORT{Hicks2021-aj,
  title       = "Implementing Responsible Artificial Intelligence in the
                 Department of Defense",
  author      = "Hicks, Kathleen",
  institution = "United States Department of Defense",
  month       =  may,
  year        =  2021,
  url         = {https://media.defense.gov/2021/may/27/2002730593/-1/-1/0/implementing-responsible-artificial-intelligence-in-the-department-of-defense.pdf}
}


@TECHREPORT{USDOD2020-lk,
  title       = "{DoD} Data Strategy: Unleashing Data to Advance the National
                 Defense Strategy",
  institution = "United States Department of Defense",
  month       =  sep,
  year        =  2020,
  url         = {https://media.defense.gov/2020/Oct/08/2002514180/-1/-1/0/DOD-DATA-STRATEGY.PDF}
}


@TECHREPORT{JAIC-Ethical-xu,
  title       = "Ethical Principles for Artificial Intelligence",
  author      = "{Joint Center for Artificial Intelligence}",
  institution = "United States Department of Defense",
  month       =  feb,
  year        =  2020,
  url         = {https://www.ai.mil/docs/Ethical_Principles_for_Artificial_Intelligence.pdf}
}
