---
title: "Trusted AI Framework Tutorial"
number-sections: true
bibliography: tai_framework.bib
---

# Tutorial

This tutorial will guide you with setting up the framework and running a simple model.
Begin by installing Git (see @sec-installing-git) and if needed installing Python (@sec-installing-python).
Using the command line, type the following to create a new directory for the new project:
(Don't type the `$` character—it is used to mark the commands typed into the terminal,)

    $ mkdir ai-tutorial

We will now go into the new directory and initialize PDM.
First, tell PDM to use the PEP 582 method of storing dependencies.

    $ cd ai-tutorial
    $ pdm config --local python.use_venv False

And now have PDM generate an initital manifest.

    $ pdm init
    Creating a pyproject.toml for PDM...
    Please enter the Python interpreter to use
    0. /opt/homebrew/opt/python@3.10/bin/python3.10 (3.10)
    1. /opt/homebrew/opt/python@3.10/bin/python3.10 (3.10)
    2. /opt/homebrew/opt/python@3.9/bin/python3.9 (3.9)
    3. /Users/dbrower/.pyenv/versions/3.9.10/bin/python3.9 (3.9)
    4. /Library/Developer/CommandLineTools/usr/bin/python3 (3.9)
    Please select (0):
    Using Python interpreter: /opt/homebrew/opt/python@3.10/bin/python3.10 (3.10)
    Would you like to create a virtualenv with /opt/homebrew/opt/python@3.10/bin/python3.10? [y/n] (y): y
    Virtualenv is created successfully at ./ai-tutorial/.venv
    Is the project a library that will be uploaded to PyPI [y/n] (n): n
    License(SPDX name) (MIT):
    Author name (Jane Doe):
    Author email (jdoe@example.com):
    Python requires('*' to allow any) (>=3.10):
    Changes are written to pyproject.toml.

PDM will give a few prompts.
For the python version, use the one that you had previously installed—usually the first option.
So chose `0`.
Type `y` to set up a virtualenv.
And then type `n` since will not be a PyPI library.
For the next four options press Enter to choose the defaults.
At the end, PDM will create a file named `pyproject.toml`.

Lets create a new git repository for this model.

    $ git init
    Initialized empty Git repository in /ai-tutorial/.git/
    $ git add .pdm.toml pyproject.toml
    $ git commit -m "Initial Commit"
    [main (root-commit) 7fc208a] Initial Commit
     1 file changed, 14 insertions(+)
     create mode 100644 .pdm.toml
     create mode 100644 pyproject.toml

## Adding the model

Now lets create a machine learning model.
For this tutorial, we will use the PyTorch [beginner quickstart project](https://pytorch.org/tutorials/beginner/basics/quickstart_tutorial.html).

Download the quickstart source code from GitHub:

    $ curl https://raw.githubusercontent.com/pytorch/tutorials/master/beginner_source/basics/quickstart_tutorial.py > quickstart_tutorial.py

This code uses some external Python models, so we need to tell PDM to fetch them:

    $ pdm add torch torchvision

Now add DVC.

    $ pdm add dvc
    $ pdm run dvc init

Lets commit our changes to the local Git repository

    $ git add .dvc .dvcignore pyproject.toml quickstart_tutorial.py
    $ git commit -m "Adding DVC and model code"

And now run the model.
The code will download the training data first, and then run 5 training epochs.

    $ pdm run python quickstart_tutorial

## DVC

The first place to start using DVC is to wrap the execution of the model with DVC, allowing DVC to track specified
dependencies, parameters and outputs.

We want to include all the files that affect the computation of the output.
A good first choice is the the Python file itself.
More subtle choices are the `pyproject.toml` and `pdm.lock` since those control the pacakges used by the source code.

    $ dvc stage add -n tutorial -d quickstart_tutorial.py -d pyproject.toml -d pdm.lock python quickstart_tutorial.py

This declares a pipeline stage named "tutorial" that executes the command `python quickstart_tutorial.py` and depends on three files.

Declaring this stage lets us (and others) reproduce the results by running `dvc repro`.
Since DVC is tracking the commands and the command line options, it is easier to share computation pipelines with others,
and we don't need to remember all the steps required to process the data.
For more complicated workflows we can make additional stages for downloading and pre-processing the data, as well as additional training steps if needed.

Additionally, DVC tracks which files we may have changed, and will only rerun the stages that depend on the changed files.
If we run the `dvc repro` command again and nothing has changed, DVC will tell us that nothing changed and doesn't execute anything.
This is identical to how `Makefiles` in software engineering work.

DVC stores the pipeline information in the `dvc.lock` file.

Add another step on downloading the data?


# Parking

## PDM Installiation info

PDM should be installed as described in the [Installation instructions](https://pdm.fming.dev/latest/#recommended-installation-method).


--------------

## Trusted Storage  {#sec-trusted-storage}

*Trusted Storage* refers to the steps needed to keep intellectual control over an AI model.
This means that you can point to the exact code used to construct each version of the model, as well as the exact training data used, how the data was preprocessed, and the parameters used for each expeirment. 
The foundation is [Git] as a version control system.
On top of that we add a storage overlay provided by the [Data Version Control][dvc] (DVC) project.
DVC provides a way to track file versions in Git, but store the contents elseware, which is useful since training data and models tend to be large files, something Git is not optimized for.

DVC also provides *pipelines* which are essentailly receipies used for each step in a training workflow.
These are similar in spirit to a *Makefile* as used in software development.

  [git]: https://git-scm.com/
  [dvc]: https://dvc.org/

## General Workflow Steps

Once a project is set up, the general workflow is:

1. Add or update data files, and download existing data files
1. Update code, run experiments
1. Check in changes to both code and data

We will now go through each step in detail.
