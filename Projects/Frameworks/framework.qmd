---
title: "Trusted AI Frameworks"
bibliography: tai_framework.bib
number-sections: true
---

## Introduction

One of the motivations behind the TrustedAI research consortium is to translate cutting edge Artificial Intelligence (AI) research into **conceptual frameworks** and **concrete tools** to facilitate the **trusted** adoption of AI based technologies by the United States Department of Defense using the United States Navy as a concrete test case. The **Frameworks Project** was intended to be a conduit for integrating both a set of **conceptual best practices** when developing, evaluating and deploying AI technologies, and a **set of software tools** that enable the conceptual frameworks. To facilitate adoption, the project looked to successful software engineering tools and principles such as [Continuous Integration/Continuous Delivery (CI/CD)](https://resources.github.com/ci-cd/) tools that widely adopt software version control systems such as [git](https://git-scm.com/) as well as software repositories like [github](https://github.com) that facilitate team based software development, automated testing and deployment, and issue tracking. Given that AI software is currently implemented in classical "Software 1.0" written in languages like Python, C++, etc, starting with trusted engineering of the traditional software stack is foundational to the practice of TrustedAI. We also recognize that there is a "AI software" lifecycle akin to the CI/CD lifecycle in traditional software engineering that correspond to the "outer ring" in @fig-framework that is **Development** of AI software, **Use** of that software in real world deployments, **Analysis** of the AI software performance i.e. &mdash;Trustworthiness&mdash;, and Re-design or Re-training of AI to better meet the underlying system requirements. At the most general level, Trustworthy AI should be **lawful**, **ethical** and **robust** throughout the AI System Lifecycle [@Smuha_undated-da].

![Conceptual Framework Principles for TrustedAI in the AI System Lifecycle](/images/graphic_concept-5.png){#fig-framework}

However, AI software is yet fundamentally different from traditional software implementation because the _software behaviors_ are _learned_ behaviors, not behavior encoded by a programmer in the program through some algorithm. This new type of software has been termed ["Software 2.0"](https://karpathy.medium.com/software-2-0-a64152b37c35) by some of the AI community and is based on the observation that the programming paradigm is being fundamentally altered from implementation of algorithms in the form of code to labeling, curating and engineering data that will be used to **define** software behavior that integrates into a **Chain of Trust** [@Toreini2020-fj] along the ML Pipeline. This observation of the critical nature of training data in the AI based software development process has lead the ["Data-centric"](https://datacentricai.org) AI discipline that aims to create principles and best practices behind systematically engineering data used to construct AI software. The Data-centric AI principles form the second foundational pillar for the frameworks in exploring and adopting tools that facilitate this "data engineering process" in **Data Collection**, **Data Preparation** and **Feature Extraction**.

At each stage of the ML Pipeline each of the **Six Dimensions of Trust** as identified by [@Liu2022-ie] can be applied. In other words, each step of the ML Pipeline should be engineered with respect to **Explainability**, **Safety & Robustness**, **Non-discrimination & Fairness**, **Accountability and Auditability**, **Environmental Well-being** and **Privacy**. The goal of the Framework tools is to integrate existing software tools or Trusted AI Project outputs with respect to each of these six dimension's of trust that can be used at each _stage_ of the ML Pipeline to create a "Toolbox" for practitioners and evaluators to utilize in enabling each of the dimensions in a modular set of software frameworks. This Framework Infrastructure connects the various components and toolboxes being developed for the Trusted AI project together into a single coherent system. The system provides standardized methods for storage and version control of code, data and documentation. There is a minimum viable vocabulary to describe experiments, as well as metadata and storage criterion for model/data outputs such as Neural Network weights. Preference is given to Open Source Software and Tools that can either be integrated into the Framework or modified by our software development teams with possible contribution back to their parent project.

## Overview

As outlined in the [Introduction](#Introduction), part of the goal for the Frameworks project was to identify tools that could be leveraged as part of the AI software lifecycle that provided functionality with respect to the dimensions of trust. One attribute of trust for (open source) software tools is that there is an active community of developers maintaining the tool and providing a broader community of support for using the tools. After initial consultation with the stakeholders and project members, it was decided that [Git](https://git-scm.com/) would be the primary software source control tool and [Github](https://github.com/) as the initial source code repository. Github is provides a commercial software source control and collaborative development environment that is friendly to open source developers in providing free public/private repositories. Other options for git source repositories exist such as [Gitlab](https://about.gitlab.com/) and the self-hosted [Gitlab Community Edition](https://gitlab.com/rluna-gitlab/gitlab-ce) that provide migration paths for git-centric source code repositories if security and privacy requirements require self-hosted options.

One way to enable Data-Centric AI [@Liang2022-yz] within the "git ecosystem" is through the use of [Data Version Control](https://dvc.org/) (DVC) that facilitates tracking of ML Models and Datasets by direct integration into the git version control system. DVC allows data to be versioned and then stored outside git repositories in a wide variety of data storage systems facilitating the use of larger datasets and storage systems than could be otherwise accommodated by git or through the use of [Git Large File Storage](https://git-lfs.github.com/). DVC also has tools to help facilitate experiment reproducibility by maintaining information about input data, configuration and code used to run an experiment all within the git source control environment. The _general_ methodology for the _core_ Trusted AI Framework is all model code, data preparation code, and training workflows are tracked in as a **Git Repository**. Training data, generated models, and analytics are tracked by **DVC** and a **separate data storage environment**.


## Military Considerations


## Methodology
Bowne et al [@Bowne2022-rc]

## Projects

Several TrustedAI projects were used as use case/test environments for the Core Framework tools. These projects provided different data/machine learning model requirements to explore how effective the tools and methodology are in

- [Knowledge Graph Construction using Natural Language Processing Tools](https://github.com/nd-crane/shipfailures-kg)
- [Paper Analytical Devices](https://nd-crane.github.io/paper-analytical-devices)
- [Stats project]()


