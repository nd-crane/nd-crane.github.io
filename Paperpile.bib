% Generated by Paperpile. Check out https://paperpile.com for more information.
% BibTeX export options can be customized via Settings -> BibTeX.

@ARTICLE{Liu2021-zw,
  title    = "Trustworthy {AI}: A Computational Perspective",
  author   = "Liu, Haochen and Wang, Yiqi and Fan, Wenqi and Liu, Xiaorui and
              Li, Yaxin and Jain, Shaili and Jain, Anil K and Tang, Jiliang",
  abstract = "In the past few decades, artificial intelligence (AI) technology
              has experienced swift developments, changing everyone's daily
              life and profoundly altering the course of human society. The
              intention of developing AI is to benefit humans, by reducing
              human labor, bringing everyday convenience to human lives, and
              promoting social good. However, recent research and AI
              applications show that AI can cause unintentional harm to humans,
              such as making unreliable decisions in safety-critical scenarios
              or undermining fairness by inadvertently discriminating against
              one group. Thus, trustworthy AI has attracted immense attention
              recently, which requires careful consideration to avoid the
              adverse effects that AI may bring to humans, so that humans can
              fully trust and live in harmony with AI technologies. Recent
              years have witnessed a tremendous amount of research on
              trustworthy AI. In this survey, we present a comprehensive survey
              of trustworthy AI from a computational perspective, to help
              readers understand the latest technologies for achieving
              trustworthy AI. Trustworthy AI is a large and complex area,
              involving various dimensions. In this work, we focus on six of
              the most crucial dimensions in achieving trustworthy AI: (i)
              Safety \& Robustness, (ii) Non-discrimination \& Fairness, (iii)
              Explainability, (iv) Privacy, (v) Accountability \& Auditability,
              and (vi) Environmental Well-Being. For each dimension, we review
              the recent related technologies according to a taxonomy and
              summarize their applications in real-world systems. We also
              discuss the accordant and conflicting interactions among
              different dimensions and discuss potential aspects for
              trustworthy AI to investigate in the future.",
  journal  = "arXiv:2107.06641 [cs]",
  month    =  jul,
  year     =  2021,
  keywords = "Trustworthiness; Computer Science - Artificial Intelligence;
              Trusted AI;Trusted AI;TAI Framework;Zotero Experiment"
}

@INPROCEEDINGS{Toreini2020-fj,
  title     = "The relationship between trust in {AI} and trustworthy machine
               learning technologies",
  booktitle = "Proceedings of the 2020 Conference on Fairness, Accountability,
               and Transparency",
  author    = "Toreini, Ehsan and Aitken, Mhairi and Coopamootoo, Kovila and
               Elliott, Karen and Zelaya, Carlos Gonzalez and van Moorsel, Aad",
  abstract  = "To design and develop AI-based systems that users and the larger
               public can justifiably trust, one needs to understand how
               machine learning technologies impact trust. To guide the design
               and implementation of trusted AI-based systems, this paper
               provides a systematic approach to relate considerations about
               trust from the social sciences to trustworthiness technologies
               proposed for AI-based services and products. We start from the
               ABI+ (Ability, Benevolence, Integrity, Predictability) framework
               augmented with a recently proposed mapping of ABI+ on qualities
               of technologies that support trust. We consider four categories
               of trustworthiness technologies for machine learning, namely
               these for Fairness, Explainability, Auditability and Safety
               (FEAS) and discuss if and how these support the required
               qualities. Moreover, trust can be impacted throughout the life
               cycle of AI-based systems, and we therefore introduce the
               concept of Chain of Trust to discuss trustworthiness
               technologies in all stages of the life cycle. In so doing we
               establish the ways in which machine learning technologies
               support trusted AI-based systems. Finally, FEAS has obvious
               relations with known frameworks and therefore we relate FEAS to
               a variety of international 'principled AI' policy and technology
               frameworks that have emerged in recent years.",
  publisher = "Association for Computing Machinery",
  pages     = "272--283",
  series    = "FAT* '20",
  month     =  jan,
  year      =  2020,
  address   = "New York, NY, USA",
  keywords  = "trustworthiness, artificial intelligence, machine learning,
               trust;Trusted AI;TAI Framework",
  location  = "Barcelona, Spain"
}

@INPROCEEDINGS{Thornton2021-hk,
  title     = "Fifty Shades of Grey: In Praise of a Nuanced Approach Towards
               Trustworthy Design",
  booktitle = "Proceedings of the 2021 {ACM} Conference on Fairness,
               Accountability, and Transparency",
  author    = "Thornton, Lauren and Knowles, Bran and Blair, Gordon",
  abstract  = "Environmental data science is uniquely placed to respond to
               essentially complex and fantastically worthy challenges related
               to arresting planetary destruction. Trust is needed for
               facilitating collaboration between scientists who may share
               datasets and algorithms, and for crafting appropriate
               science-based policies. Achieving this trust is particularly
               challenging because of the numerous complexities, multi-scale
               variables, interdependencies and multi-level uncertainties
               inherent in environmental data science. Virtual Labs---easily
               accessible online environments provisioning access to datasets,
               analysis and visualisations---are socio-technical systems which,
               if carefully designed, might address these challenges and
               promote trust in a variety of ways. In addition to various
               system properties that can be utilised in support of effective
               collaboration, certain features which are commonly seen to
               benefit trust---transparency and provenance in
               particular---appear applicable to promoting trust in and through
               Virtual Labs. Attempting to realise these features in their
               design reveals, however, that their implementation is more
               nuanced and complex than it would appear. Using the lens of
               affordances, we argue for the need to carefully articulate these
               features, with consideration of multiple stakeholder needs on
               balance, so that these Virtual Labs do in fact promote trust. We
               argue that these features not be conceived as widgets that can
               be imported into a given context to promote trust; rather,
               whether they promote trust is a function of how systematically
               designers consider various (potentially conflicting) stakeholder
               trust needs.",
  publisher = "Association for Computing Machinery",
  pages     = "64--76",
  series    = "FAccT '21",
  month     =  mar,
  year      =  2021,
  address   = "New York, NY, USA",
  keywords  = "Affordances, Trust, Environmental Data Science, Virtual Research
               Environments;Trusted AI;TAI Framework",
  location  = "Virtual Event, Canada"
}

@BOOK{Corporate-body_CNECTDirectorate-General_for_Communications_Networks2019-gd,
  title     = "Ethics guidelines for trustworthy {AI}",
  author    = "{corporate-body. CNECT:Directorate-General for Communications
               Networks} and {Content} and {Technology} and {null.agent.Grupa
               ekspert{\'o}w wysokiego szczebla ds. sztucznej
               inteligencji:Grupa ekspert{\'o}w wysokiego szczebla ds.
               sztucznej inteligencji}",
  abstract  = "The aim of the Guidelines is to promote Trustworthy AI.
               Trustworthy AI has three components, which should be met
               throughout the system's entire life cycle: (1) it should be
               lawful, complying with all applicable laws and regulations (2)
               it should be ethical, ensuring adherence to ethical principles
               and values and (3) it should be robust, both from a technical
               and social perspective since, even with good intentions, AI
               systems can cause unintentional harm. Each component in itself
               is necessary but not sufficient for the achievement of
               Trustworthy AI. Ideally, all three components work in harmony
               and overlap in their operation. If, in practice, tensions arise
               between these components, society should endeavour to align
               them.",
  publisher = "Publications Office of the European Union",
  month     =  nov,
  year      =  2019,
  keywords  = "Trusted AI;TAI Framework",
  language  = "en"
}

@TECHREPORT{Smuha_undated-da,
  title     = "Ethics guidelines for trustworthy {AI}",
  editor    = "Smuha, Nathalie",
  abstract  = "On 8 April 2019, the High-Level Expert Group on AI presented
               Ethics Guidelines for Trustworthy Artificial Intelligence. This
               followed the publication of the guidelines' first draft in
               December 2018 on which more than 500 comments were received
               through an open consultation.",
  publisher = "European Commission",
  keywords  = "TAI Framework",
  language  = "en"
}

@ARTICLE{Liang2022-yz,
  title     = "Advances, challenges and opportunities in creating data for
               trustworthy {AI}",
  author    = "Liang, Weixin and Tadesse, Girmaw Abebe and Ho, Daniel and Li,
               Fei-Fei and Zaharia, Matei and Zhang, Ce and Zou, James",
  abstract  = "As artificial intelligence (AI) transitions from research to
               deployment, creating the appropriate datasets and data pipelines
               to develop and evaluate AI models is increasingly the biggest
               challenge. Automated AI model builders that are publicly
               available can now achieve top performance in many applications.
               In contrast, the design and sculpting of the data used to
               develop AI often rely on bespoke manual work, and they
               critically affect the trustworthiness of the model. This
               Perspective discusses key considerations for each stage of the
               data-for-AI pipeline---starting from data design to data
               sculpting (for example, cleaning, valuation and annotation) and
               data evaluation---to make AI more reliable. We highlight
               technical advances that help to make the data-for-AI pipeline
               more scalable and rigorous. Furthermore, we discuss how recent
               data regulations and policies can impact AI. It has become
               rapidly clear in the past few years that the creation, use and
               maintenance of high-quality annotated datasets for robust and
               reliable AI applications requires careful attention. This
               Perspective discusses challenges, considerations and best
               practices for various stages in the data-to-AI pipeline, to
               encourage a more data-centric approach.",
  journal   = "Nat Mach Intell",
  publisher = "Springer Science and Business Media LLC",
  pages     = "1--9",
  month     =  aug,
  year      =  2022,
  keywords  = "Overleaf;Toward Unified Models;Trusted AI;TAI Framework",
  language  = "en"
}

@TECHREPORT{Benjamin2022-rc,
  title       = "Implementing Responsible {AI}: Proposed Framework for Data
                 Licensing",
  author      = "Benjamin, Bowne, Andrew And",
  publisher   = "George Mason University School of Business",
  number      =  10,
  institution = "George Mason University Center for Government Contracting",
  month       =  apr,
  year        =  2022,
  keywords    = "TAI Framework"
}
